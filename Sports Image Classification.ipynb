{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ll2IUBGrf0OH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import csv  \n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import keras\n",
        "import tensorflow.compat.v2 as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm.notebook as tq\n",
        "from tqdm.auto import tqdm\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D,Dropout,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import layer_utils\n",
        "from keras.engine import training\n",
        "from keras.utils import data_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "iCxYmwWbglNB",
        "outputId": "8bcdd36c-ec9c-4b47-d429-1b373ad902e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa753ea3-dac3-4fcc-9eac-4269ba05e103\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa753ea3-dac3-4fcc-9eac-4269ba05e103\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/ \n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5JeOh1Ei2kd",
        "outputId": "fdb80363-1612-4d3e-c348-665c01d5bfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading nn23-sports-image-classification.zip to /content\n",
            " 95% 249M/262M [00:01<00:00, 177MB/s]\n",
            "100% 262M/262M [00:01<00:00, 158MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c nn23-sports-image-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b2MHLHUHjUSJ"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/nn23-sports-image-classification.zip','r') as ziphandler:\n",
        "  ziphandler.extractall('/content/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cvT8oORtk6BO"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '/content/data/Train'\n",
        "TEST_DIR = '/content/data/Test'\n",
        "IMG_SIZE = 250\n",
        "LR = 0.0001\n",
        "batch_size = 64\n",
        "MODEL_NAME = 'Sports Classification'\n",
        "CHANNEL_AXIS = -1\n",
        "TF_WEIGHTS_PATH_NO_TOP = (\n",
        "    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n",
        "    \"xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtkx29ls8AUA"
      },
      "outputs": [],
      "source": [
        "def return_label(img):\n",
        "  return img.split('_')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DndzOISXla73"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_train_data():\n",
        "    training_data = []\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        path = os.path.join(TRAIN_DIR, img)\n",
        "        folder_path = os.path.join(TRAIN_DIR, return_label(img))\n",
        "        if not os.path.exists(folder_path):\n",
        "          os.makedirs(folder_path)\n",
        "        dest = os.path.join(folder_path, img)\n",
        "        shutil.move(path,dest)\n",
        "    return training_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "247cfd28683647ab82d37d4f2110365e",
            "f4a515c8217c4c61b1b44fa88444dcfc",
            "b7a5c41e67a04673bc0cbea396b7f824",
            "bbc592b7d5704da4bb442e5c81f2c5c2",
            "c189c858332d4d508cbf5fc0369017b2",
            "318ef2ca07024e40a8057332cabd3bf4",
            "e2a762e792e64d3bbad74593203b76fc",
            "a5d23a5b50af47d6b8db54f74dd9528e",
            "3ef09a21a64d4ef097a5d45f15d88316",
            "5729337a8efb48b5a44f1c454d2a2f4f",
            "045b4cb3edfd4ec2988bdf032075c14c"
          ]
        },
        "id": "6Dvoow_zl3bC",
        "outputId": "37d7d063-94d6-4600-f6f5-23de3728e3ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1681 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "247cfd28683647ab82d37d4f2110365e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = create_train_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z-2uLuGYlJk",
        "outputId": "3d08112e-a0e4-4514-a645-55fc54c96276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1346 images belonging to 6 classes.\n",
            "Found 335 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Get the data\n",
        "trdata = ImageDataGenerator(validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "train_ds = trdata.flow_from_directory(directory=\"/content/data/Train\",target_size=(IMG_SIZE,IMG_SIZE),subset='training')\n",
        "\n",
        "\n",
        "val_ds = trdata.flow_from_directory(directory=\"/content/data/Train\",target_size=(IMG_SIZE,IMG_SIZE),subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y32IOUXTkZw",
        "outputId": "545acaa1-4988-48a3-ca46-e3433e7a9fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              8392704   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 24582     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,278,766\n",
            "Trainable params: 29,224,238\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.8056 - accuracy: 0.7303\n",
            "Epoch 1: val_accuracy improved from -inf to 0.85373, saving model to xception.h5\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.8056 - accuracy: 0.7303 - val_loss: 0.4184 - val_accuracy: 0.8537\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9450\n",
            "Epoch 2: val_accuracy improved from 0.85373 to 0.94925, saving model to xception.h5\n",
            "43/43 [==============================] - 44s 1s/step - loss: 0.1590 - accuracy: 0.9450 - val_loss: 0.1762 - val_accuracy: 0.9493\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9792\n",
            "Epoch 3: val_accuracy improved from 0.94925 to 0.96418, saving model to xception.h5\n",
            "43/43 [==============================] - 42s 972ms/step - loss: 0.0763 - accuracy: 0.9792 - val_loss: 0.0935 - val_accuracy: 0.9642\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9889\n",
            "Epoch 4: val_accuracy improved from 0.96418 to 0.96716, saving model to xception.h5\n",
            "43/43 [==============================] - 42s 974ms/step - loss: 0.0419 - accuracy: 0.9889 - val_loss: 0.1553 - val_accuracy: 0.9672\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9881\n",
            "Epoch 5: val_accuracy did not improve from 0.96716\n",
            "43/43 [==============================] - 43s 989ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 0.1326 - val_accuracy: 0.9672\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9911\n",
            "Epoch 6: val_accuracy improved from 0.96716 to 0.97313, saving model to xception.h5\n",
            "43/43 [==============================] - 44s 1s/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.0867 - val_accuracy: 0.9731\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9881\n",
            "Epoch 7: val_accuracy did not improve from 0.97313\n",
            "43/43 [==============================] - 41s 948ms/step - loss: 0.0292 - accuracy: 0.9881 - val_loss: 0.0992 - val_accuracy: 0.9642\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9903\n",
            "Epoch 8: val_accuracy did not improve from 0.97313\n",
            "43/43 [==============================] - 41s 943ms/step - loss: 0.0353 - accuracy: 0.9903 - val_loss: 0.1011 - val_accuracy: 0.9642\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9903\n",
            "Epoch 9: val_accuracy did not improve from 0.97313\n",
            "43/43 [==============================] - 41s 947ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.1306 - val_accuracy: 0.9612\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9896\n",
            "Epoch 10: val_accuracy improved from 0.97313 to 0.98209, saving model to xception.h5\n",
            "43/43 [==============================] - 43s 982ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 0.0751 - val_accuracy: 0.9821\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9955\n",
            "Epoch 11: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 950ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0799 - val_accuracy: 0.9761\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9948\n",
            "Epoch 12: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 42s 965ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.0830 - val_accuracy: 0.9821\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9889\n",
            "Epoch 13: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 962ms/step - loss: 0.0461 - accuracy: 0.9889 - val_loss: 0.1327 - val_accuracy: 0.9612\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9955\n",
            "Epoch 14: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 951ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.0948 - val_accuracy: 0.9791\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9963\n",
            "Epoch 15: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 944ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0856 - val_accuracy: 0.9821\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9926\n",
            "Epoch 16: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 942ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.1393 - val_accuracy: 0.9672\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9933\n",
            "Epoch 17: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 940ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0843 - val_accuracy: 0.9791\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9941\n",
            "Epoch 18: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 42s 974ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1005 - val_accuracy: 0.9672\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9926\n",
            "Epoch 19: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 945ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.1116 - val_accuracy: 0.9791\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9970\n",
            "Epoch 20: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 943ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0857 - val_accuracy: 0.9701\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
            "Epoch 21: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 943ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0903 - val_accuracy: 0.9731\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9970\n",
            "Epoch 22: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 941ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.1081 - val_accuracy: 0.9642\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978\n",
            "Epoch 23: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 938ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0642 - val_accuracy: 0.9821\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9941\n",
            "Epoch 24: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 42s 977ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.1118 - val_accuracy: 0.9672\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n",
            "Epoch 25: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 40s 933ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0966 - val_accuracy: 0.9612\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9970\n",
            "Epoch 26: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 944ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.1756 - val_accuracy: 0.9612\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9948\n",
            "Epoch 27: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 40s 957ms/step - loss: 0.0131 - accuracy: 0.9948 - val_loss: 0.1004 - val_accuracy: 0.9731\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9955\n",
            "Epoch 28: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 940ms/step - loss: 0.0234 - accuracy: 0.9955 - val_loss: 0.1565 - val_accuracy: 0.9522\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9896\n",
            "Epoch 29: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 41s 946ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.0909 - val_accuracy: 0.9821\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
            "Epoch 30: val_accuracy did not improve from 0.98209\n",
            "43/43 [==============================] - 43s 984ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0729 - val_accuracy: 0.9761\n",
            "Epoch 30: early stopping\n"
          ]
        }
      ],
      "source": [
        "# xception model\n",
        "layers = tf.keras.layers\n",
        "model = Sequential()\n",
        "img_input = layers.Input(shape=[IMG_SIZE, IMG_SIZE, 3])\n",
        " # Block 1\n",
        "x = layers.Conv2D(\n",
        "        32, (3, 3), strides=(2, 2), use_bias=False, name=\"block1_conv1\"\n",
        "    )(img_input)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block1_conv1_bn\")(x)\n",
        "x = layers.Activation(\"relu\", name=\"block1_conv1_act\")(x)\n",
        "x = layers.Conv2D(64, (3, 3), use_bias=False, name=\"block1_conv2\")(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block1_conv2_bn\")(x)\n",
        "x = layers.Activation(\"relu\", name=\"block1_conv2_act\")(x)\n",
        "\n",
        "residual = layers.Conv2D(\n",
        "        128, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n",
        "    )(x)\n",
        "residual = layers.BatchNormalization(axis=CHANNEL_AXIS)(residual)\n",
        "\n",
        "x = layers.SeparableConv2D(\n",
        "        128, (3, 3), padding=\"same\", use_bias=False, name=\"block2_sepconv1\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block2_sepconv1_bn\")(\n",
        "        x\n",
        "    )\n",
        "x = layers.Activation(\"relu\", name=\"block2_sepconv2_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        128, (3, 3), padding=\"same\", use_bias=False, name=\"block2_sepconv2\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block2_sepconv2_bn\")(\n",
        "        x\n",
        "    )\n",
        "\n",
        "x = layers.MaxPooling2D(\n",
        "        (3, 3), strides=(2, 2), padding=\"same\", name=\"block2_pool\"\n",
        "    )(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "residual = layers.Conv2D(\n",
        "        256, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n",
        "    )(x)\n",
        "residual = layers.BatchNormalization(axis=CHANNEL_AXIS)(residual)\n",
        "\n",
        "x = layers.Activation(\"relu\", name=\"block3_sepconv1_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        256, (3, 3), padding=\"same\", use_bias=False, name=\"block3_sepconv1\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block3_sepconv1_bn\")(\n",
        "        x\n",
        "    )\n",
        "x = layers.Activation(\"relu\", name=\"block3_sepconv2_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        256, (3, 3), padding=\"same\", use_bias=False, name=\"block3_sepconv2\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block3_sepconv2_bn\")(\n",
        "        x\n",
        "    )\n",
        "\n",
        "x = layers.MaxPooling2D(\n",
        "        (3, 3), strides=(2, 2), padding=\"same\", name=\"block3_pool\"\n",
        "    )(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "residual = layers.Conv2D(\n",
        "        728, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n",
        "    )(x)\n",
        "residual = layers.BatchNormalization(axis=CHANNEL_AXIS)(residual)\n",
        "\n",
        "x = layers.Activation(\"relu\", name=\"block4_sepconv1_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        728, (3, 3), padding=\"same\", use_bias=False, name=\"block4_sepconv1\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block4_sepconv1_bn\")(\n",
        "        x\n",
        "    )\n",
        "x = layers.Activation(\"relu\", name=\"block4_sepconv2_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        728, (3, 3), padding=\"same\", use_bias=False, name=\"block4_sepconv2\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(axis=CHANNEL_AXIS, name=\"block4_sepconv2_bn\")(\n",
        "        x\n",
        "    )\n",
        "\n",
        "x = layers.MaxPooling2D(\n",
        "        (3, 3), strides=(2, 2), padding=\"same\", name=\"block4_pool\"\n",
        "    )(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "for i in range(8):\n",
        "  residual = x\n",
        "  prefix = \"block\" + str(i + 5)\n",
        "\n",
        "  x = layers.Activation(\"relu\", name=prefix + \"_sepconv1_act\")(x)\n",
        "  x = layers.SeparableConv2D(\n",
        "            728,\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            name=prefix + \"_sepconv1\",\n",
        "        )(x)\n",
        "  x = layers.BatchNormalization(\n",
        "            axis=CHANNEL_AXIS, name=prefix + \"_sepconv1_bn\"\n",
        "        )(x)\n",
        "  x = layers.Activation(\"relu\", name=prefix + \"_sepconv2_act\")(x)\n",
        "  x = layers.SeparableConv2D(\n",
        "            728,\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            name=prefix + \"_sepconv2\",\n",
        "        )(x)\n",
        "  x = layers.BatchNormalization(\n",
        "            axis=CHANNEL_AXIS, name=prefix + \"_sepconv2_bn\"\n",
        "        )(x)\n",
        "  x = layers.Activation(\"relu\", name=prefix + \"_sepconv3_act\")(x)\n",
        "  x = layers.SeparableConv2D(\n",
        "            728,\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            name=prefix + \"_sepconv3\",\n",
        "        )(x)\n",
        "  x = layers.BatchNormalization(\n",
        "            axis=CHANNEL_AXIS, name=prefix + \"_sepconv3_bn\"\n",
        "        )(x)\n",
        "\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "residual = layers.Conv2D(\n",
        "        1024, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n",
        "    )(x)\n",
        "residual = layers.BatchNormalization(axis=CHANNEL_AXIS)(residual)\n",
        "\n",
        "x = layers.Activation(\"relu\", name=\"block13_sepconv1_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        728, (3, 3), padding=\"same\", use_bias=False, name=\"block13_sepconv1\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(\n",
        "        axis=CHANNEL_AXIS, name=\"block13_sepconv1_bn\"\n",
        "    )(x)\n",
        "x = layers.Activation(\"relu\", name=\"block13_sepconv2_act\")(x)\n",
        "x = layers.SeparableConv2D(\n",
        "        1024, (3, 3), padding=\"same\", use_bias=False, name=\"block13_sepconv2\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(\n",
        "        axis=CHANNEL_AXIS, name=\"block13_sepconv2_bn\"\n",
        "    )(x)\n",
        "\n",
        "x = layers.MaxPooling2D(\n",
        "        (3, 3), strides=(2, 2), padding=\"same\", name=\"block13_pool\"\n",
        "    )(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "x = layers.SeparableConv2D(\n",
        "        1536, (3, 3), padding=\"same\", use_bias=False, name=\"block14_sepconv1\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(\n",
        "        axis=CHANNEL_AXIS, name=\"block14_sepconv1_bn\"\n",
        "    )(x)\n",
        "x = layers.Activation(\"relu\", name=\"block14_sepconv1_act\")(x)\n",
        "\n",
        "x = layers.SeparableConv2D(\n",
        "        2048, (3, 3), padding=\"same\", use_bias=False, name=\"block14_sepconv2\"\n",
        "    )(x)\n",
        "x = layers.BatchNormalization(\n",
        "        axis=CHANNEL_AXIS, name=\"block14_sepconv2_bn\"\n",
        "    )(x)\n",
        "x = layers.Activation(\"relu\", name=\"block14_sepconv2_act\")(x)\n",
        "\n",
        "m = training.Model(img_input, x, name=\"xception\")\n",
        "weights_path = data_utils.get_file(\n",
        "                \"xception_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
        "                TF_WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir=\"models\",\n",
        "                file_hash=\"b0042744bf5b25fce3cb969f33bebb97\",\n",
        "            )\n",
        "m.load_weights(weights_path)\n",
        "model.add(m)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "\n",
        "for layer in model.layers:\n",
        "  layer.trainable = True\n",
        "# Add Optimizer and check accuracy metrics\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "# Check model summary\n",
        "print(model.summary())\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"xception.h5\", monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "                             save_weights_only=False, mode='auto', period=1)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit(train_ds, validation_data=val_ds, epochs=100,\n",
        "                           callbacks=[checkpoint, earlystop])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16\n",
        "\n",
        "layers = tf.keras.layers\n",
        "\n",
        "WEIGHTS_PATH_NO_TOP = (\n",
        "    \"https://storage.googleapis.com/tensorflow/\"\n",
        "    \"keras-applications/vgg16/\"\n",
        "    \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "conv_input = layers.Input(shape=[IMG_SIZE, IMG_SIZE, 3])\n",
        " # Block 1\n",
        "x = layers.Conv2D(\n",
        "        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\"\n",
        "    )(conv_input)\n",
        "x = layers.Conv2D(\n",
        "        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\"\n",
        "    )(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
        "\n",
        "    # Block 2\n",
        "x = layers.Conv2D(\n",
        "        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\"\n",
        "    )(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
        "\n",
        "    # Block 3\n",
        "x = layers.Conv2D(\n",
        "        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\"\n",
        "    )(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
        "\n",
        "    # Block 4\n",
        "x = layers.Conv2D(\n",
        "        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\"\n",
        "    )(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
        "\n",
        "    # Block 5\n",
        "x = layers.Conv2D(\n",
        "        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\"\n",
        "    )(x)\n",
        "x = layers.Conv2D(\n",
        "        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\"\n",
        "    )(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
        "\n",
        "m = training.Model(conv_input, x, name=\"vgg16\")\n",
        "weights_path = data_utils.get_file(\n",
        "                \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir=\"models\",\n",
        "                file_hash=\"6d6bbae143d832006294945121d1f1fc\",\n",
        "            )\n",
        "m.load_weights(weights_path)\n",
        "model.add(m)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "\n",
        "for layer in model.layers:\n",
        "  layer.trainable = True\n",
        "# Add Optimizer and check accuracy metrics\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "# Check model summary\n",
        "print(model.summary())\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "                             save_weights_only=False, mode='auto', period=1)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit(train_ds, validation_data=val_ds, epochs=100,\n",
        "                           callbacks=[checkpoint, earlystop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy2tqyOkxWg3",
        "outputId": "9c56f571-dc22-419d-87d5-cbae1d69ffed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1346 images belonging to 6 classes.\n",
            "Found 335 images belonging to 6 classes.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_4   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 24582     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,840,518\n",
            "Trainable params: 16,840,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.6216 - accuracy: 0.3477\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55224, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 39s 889ms/step - loss: 1.6216 - accuracy: 0.3477 - val_loss: 1.2029 - val_accuracy: 0.5522\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.3536 - accuracy: 0.4933\n",
            "Epoch 2: val_accuracy improved from 0.55224 to 0.59701, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 36s 845ms/step - loss: 1.3536 - accuracy: 0.4933 - val_loss: 1.0046 - val_accuracy: 0.5970\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.0157 - accuracy: 0.6174\n",
            "Epoch 3: val_accuracy improved from 0.59701 to 0.72537, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 36s 836ms/step - loss: 1.0157 - accuracy: 0.6174 - val_loss: 0.7192 - val_accuracy: 0.7254\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.0389 - accuracy: 0.6404\n",
            "Epoch 4: val_accuracy improved from 0.72537 to 0.77015, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 37s 867ms/step - loss: 1.0389 - accuracy: 0.6404 - val_loss: 0.7023 - val_accuracy: 0.7701\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7583 - accuracy: 0.7452\n",
            "Epoch 5: val_accuracy improved from 0.77015 to 0.82090, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 36s 839ms/step - loss: 0.7583 - accuracy: 0.7452 - val_loss: 0.5910 - val_accuracy: 0.8209\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.7379 - accuracy: 0.7593\n",
            "Epoch 6: val_accuracy did not improve from 0.82090\n",
            "43/43 [==============================] - 36s 830ms/step - loss: 0.7379 - accuracy: 0.7593 - val_loss: 0.6287 - val_accuracy: 0.8060\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.8001\n",
            "Epoch 7: val_accuracy improved from 0.82090 to 0.86269, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 37s 851ms/step - loss: 0.6015 - accuracy: 0.8001 - val_loss: 0.3942 - val_accuracy: 0.8627\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8403\n",
            "Epoch 8: val_accuracy did not improve from 0.86269\n",
            "43/43 [==============================] - 36s 828ms/step - loss: 0.4915 - accuracy: 0.8403 - val_loss: 0.6153 - val_accuracy: 0.8149\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.8113\n",
            "Epoch 9: val_accuracy improved from 0.86269 to 0.88060, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 37s 851ms/step - loss: 0.5662 - accuracy: 0.8113 - val_loss: 0.3947 - val_accuracy: 0.8806\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.8484\n",
            "Epoch 10: val_accuracy improved from 0.88060 to 0.88657, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 37s 844ms/step - loss: 0.4490 - accuracy: 0.8484 - val_loss: 0.3753 - val_accuracy: 0.8866\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8900\n",
            "Epoch 11: val_accuracy did not improve from 0.88657\n",
            "43/43 [==============================] - 36s 826ms/step - loss: 0.3513 - accuracy: 0.8900 - val_loss: 0.5579 - val_accuracy: 0.8328\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.8848\n",
            "Epoch 12: val_accuracy did not improve from 0.88657\n",
            "43/43 [==============================] - 36s 842ms/step - loss: 0.3722 - accuracy: 0.8848 - val_loss: 0.3414 - val_accuracy: 0.8866\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8908\n",
            "Epoch 13: val_accuracy did not improve from 0.88657\n",
            "43/43 [==============================] - 36s 842ms/step - loss: 0.3512 - accuracy: 0.8908 - val_loss: 0.4703 - val_accuracy: 0.8358\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8848\n",
            "Epoch 14: val_accuracy did not improve from 0.88657\n",
            "43/43 [==============================] - 36s 826ms/step - loss: 0.3583 - accuracy: 0.8848 - val_loss: 0.4042 - val_accuracy: 0.8716\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9302\n",
            "Epoch 15: val_accuracy improved from 0.88657 to 0.92239, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 36s 835ms/step - loss: 0.2232 - accuracy: 0.9302 - val_loss: 0.2359 - val_accuracy: 0.9224\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9324\n",
            "Epoch 16: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 36s 841ms/step - loss: 0.2111 - accuracy: 0.9324 - val_loss: 0.3410 - val_accuracy: 0.8896\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9027\n",
            "Epoch 17: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 36s 824ms/step - loss: 0.3026 - accuracy: 0.9027 - val_loss: 0.2831 - val_accuracy: 0.9045\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9235\n",
            "Epoch 18: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 36s 838ms/step - loss: 0.2482 - accuracy: 0.9235 - val_loss: 0.3062 - val_accuracy: 0.9015\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9398\n",
            "Epoch 19: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 36s 861ms/step - loss: 0.1864 - accuracy: 0.9398 - val_loss: 0.3271 - val_accuracy: 0.9075\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9525\n",
            "Epoch 20: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 36s 824ms/step - loss: 0.1652 - accuracy: 0.9525 - val_loss: 0.3735 - val_accuracy: 0.9104\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9473\n",
            "Epoch 21: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 36s 838ms/step - loss: 0.1569 - accuracy: 0.9473 - val_loss: 0.3773 - val_accuracy: 0.9075\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.9242\n",
            "Epoch 22: val_accuracy did not improve from 0.92239\n",
            "43/43 [==============================] - 37s 847ms/step - loss: 0.2666 - accuracy: 0.9242 - val_loss: 1.1357 - val_accuracy: 0.7075\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.9079\n",
            "Epoch 23: val_accuracy improved from 0.92239 to 0.93134, saving model to vgg16_1.h5\n",
            "43/43 [==============================] - 36s 831ms/step - loss: 0.3186 - accuracy: 0.9079 - val_loss: 0.2576 - val_accuracy: 0.9313\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9591\n",
            "Epoch 24: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 832ms/step - loss: 0.1332 - accuracy: 0.9591 - val_loss: 0.2538 - val_accuracy: 0.9284\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9718\n",
            "Epoch 25: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 836ms/step - loss: 0.0951 - accuracy: 0.9718 - val_loss: 0.3518 - val_accuracy: 0.9194\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9643\n",
            "Epoch 26: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 827ms/step - loss: 0.1036 - accuracy: 0.9643 - val_loss: 0.3669 - val_accuracy: 0.9015\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9807\n",
            "Epoch 27: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 39s 899ms/step - loss: 0.0636 - accuracy: 0.9807 - val_loss: 0.4335 - val_accuracy: 0.9045\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9547\n",
            "Epoch 28: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 37s 858ms/step - loss: 0.1473 - accuracy: 0.9547 - val_loss: 0.3271 - val_accuracy: 0.9075\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9443\n",
            "Epoch 29: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 819ms/step - loss: 0.1699 - accuracy: 0.9443 - val_loss: 0.4365 - val_accuracy: 0.9015\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9629\n",
            "Epoch 30: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 41s 941ms/step - loss: 0.1089 - accuracy: 0.9629 - val_loss: 0.4910 - val_accuracy: 0.8806\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9814\n",
            "Epoch 31: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 839ms/step - loss: 0.0696 - accuracy: 0.9814 - val_loss: 0.2983 - val_accuracy: 0.9254\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9770\n",
            "Epoch 32: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 825ms/step - loss: 0.0715 - accuracy: 0.9770 - val_loss: 0.3696 - val_accuracy: 0.8955\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9814\n",
            "Epoch 33: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 831ms/step - loss: 0.0662 - accuracy: 0.9814 - val_loss: 0.2768 - val_accuracy: 0.9313\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9762\n",
            "Epoch 34: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 837ms/step - loss: 0.0623 - accuracy: 0.9762 - val_loss: 0.4475 - val_accuracy: 0.9134\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9733\n",
            "Epoch 35: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 35s 819ms/step - loss: 0.0755 - accuracy: 0.9733 - val_loss: 0.3279 - val_accuracy: 0.9134\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9688\n",
            "Epoch 36: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 35s 819ms/step - loss: 0.0904 - accuracy: 0.9688 - val_loss: 0.5443 - val_accuracy: 0.9075\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9577\n",
            "Epoch 37: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 37s 868ms/step - loss: 0.1447 - accuracy: 0.9577 - val_loss: 0.3770 - val_accuracy: 0.9254\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9718\n",
            "Epoch 38: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 824ms/step - loss: 0.0751 - accuracy: 0.9718 - val_loss: 0.3140 - val_accuracy: 0.9164\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9881\n",
            "Epoch 39: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 35s 820ms/step - loss: 0.0503 - accuracy: 0.9881 - val_loss: 0.3299 - val_accuracy: 0.9284\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9629\n",
            "Epoch 40: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 37s 850ms/step - loss: 0.1220 - accuracy: 0.9629 - val_loss: 0.5490 - val_accuracy: 0.8716\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9733\n",
            "Epoch 41: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 35s 813ms/step - loss: 0.0741 - accuracy: 0.9733 - val_loss: 0.3711 - val_accuracy: 0.9075\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9829\n",
            "Epoch 42: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 36s 820ms/step - loss: 0.0567 - accuracy: 0.9829 - val_loss: 0.2135 - val_accuracy: 0.9313\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9911\n",
            "Epoch 43: val_accuracy did not improve from 0.93134\n",
            "43/43 [==============================] - 37s 846ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.2578 - val_accuracy: 0.9284\n",
            "Epoch 43: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1217d9e2b97d4dfaa9f4051d5c577b36",
            "7f1288fdb0f843bbb2bd9c78e515ea2f",
            "6bf6ef6d05454fd6b942da05ac84be84",
            "028879d2516b4a25a825a6f6b3732241",
            "33b066f6920d4ea69da095000036fcb5",
            "654cf142af7249f2906fe37c403dd377",
            "8802e886a6194cc4942f7fc80e0a65aa",
            "07d2bfec13bd4a408d0278d65a8cc56c",
            "d20ffed6791a41158b80c777e7f6a055",
            "dcae0f77daef4ad8a6c989e92ed153c7",
            "516bd59ae3e14e409eb6003bf9d7cdd1"
          ]
        },
        "id": "cefrMm6Dadh4",
        "outputId": "60bd9aed-bf23-4ff5-dc74-b5a190636153"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/688 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1217d9e2b97d4dfaa9f4051d5c577b36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ],
      "source": [
        "model_name = 'xception.h5'\n",
        "saved_model = load_model(model_name, compile = False)\n",
        "with open('results.csv', 'w', encoding='UTF8',newline='') as f:\n",
        "  header = [\"image_name\",\"label\"]\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(header)\n",
        "  for img in tq.tqdm(os.listdir(TEST_DIR)):\n",
        "    path = os.path.join(TEST_DIR, img)\n",
        "    img_arr = tf.keras.utils.load_img(path,target_size=(IMG_SIZE,IMG_SIZE))\n",
        "    img_arr = np.asarray(img_arr)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    prediction = saved_model.predict(img_arr)\n",
        "    data = [img,np.argmax(prediction)]\n",
        "    writer.writerow(data)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__aAxu5ia3fs"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "247cfd28683647ab82d37d4f2110365e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a515c8217c4c61b1b44fa88444dcfc",
              "IPY_MODEL_b7a5c41e67a04673bc0cbea396b7f824",
              "IPY_MODEL_bbc592b7d5704da4bb442e5c81f2c5c2"
            ],
            "layout": "IPY_MODEL_c189c858332d4d508cbf5fc0369017b2"
          }
        },
        "f4a515c8217c4c61b1b44fa88444dcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318ef2ca07024e40a8057332cabd3bf4",
            "placeholder": "​",
            "style": "IPY_MODEL_e2a762e792e64d3bbad74593203b76fc",
            "value": "100%"
          }
        },
        "b7a5c41e67a04673bc0cbea396b7f824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d23a5b50af47d6b8db54f74dd9528e",
            "max": 1681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ef09a21a64d4ef097a5d45f15d88316",
            "value": 1681
          }
        },
        "bbc592b7d5704da4bb442e5c81f2c5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5729337a8efb48b5a44f1c454d2a2f4f",
            "placeholder": "​",
            "style": "IPY_MODEL_045b4cb3edfd4ec2988bdf032075c14c",
            "value": " 1681/1681 [00:00&lt;00:00, 17640.41it/s]"
          }
        },
        "c189c858332d4d508cbf5fc0369017b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318ef2ca07024e40a8057332cabd3bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a762e792e64d3bbad74593203b76fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d23a5b50af47d6b8db54f74dd9528e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef09a21a64d4ef097a5d45f15d88316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5729337a8efb48b5a44f1c454d2a2f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045b4cb3edfd4ec2988bdf032075c14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1217d9e2b97d4dfaa9f4051d5c577b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f1288fdb0f843bbb2bd9c78e515ea2f",
              "IPY_MODEL_6bf6ef6d05454fd6b942da05ac84be84",
              "IPY_MODEL_028879d2516b4a25a825a6f6b3732241"
            ],
            "layout": "IPY_MODEL_33b066f6920d4ea69da095000036fcb5"
          }
        },
        "7f1288fdb0f843bbb2bd9c78e515ea2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_654cf142af7249f2906fe37c403dd377",
            "placeholder": "​",
            "style": "IPY_MODEL_8802e886a6194cc4942f7fc80e0a65aa",
            "value": "100%"
          }
        },
        "6bf6ef6d05454fd6b942da05ac84be84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d2bfec13bd4a408d0278d65a8cc56c",
            "max": 688,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d20ffed6791a41158b80c777e7f6a055",
            "value": 688
          }
        },
        "028879d2516b4a25a825a6f6b3732241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcae0f77daef4ad8a6c989e92ed153c7",
            "placeholder": "​",
            "style": "IPY_MODEL_516bd59ae3e14e409eb6003bf9d7cdd1",
            "value": " 688/688 [00:49&lt;00:00,  7.34it/s]"
          }
        },
        "33b066f6920d4ea69da095000036fcb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654cf142af7249f2906fe37c403dd377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8802e886a6194cc4942f7fc80e0a65aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d2bfec13bd4a408d0278d65a8cc56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20ffed6791a41158b80c777e7f6a055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcae0f77daef4ad8a6c989e92ed153c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516bd59ae3e14e409eb6003bf9d7cdd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}